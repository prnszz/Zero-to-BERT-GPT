{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "BERTモデルは[BERT: 言語理解のための双方向Transformerの事前学習](https://arxiv.org/abs/1810.04805)で提案されました。「Bidirectional Encoder Representation with Transformers」の略です。簡単に言えば、BERTはエンコーダーを通してデータまたは単語埋め込みからパターンや表現を抽出します。エンコーダー自体は積み重ねられたトランスフォーマーアーキテクチャです。これは双方向トランスフォーマーで、トレーニング中に語彙の左右両方のコンテキストを考慮してパターンや表現を抽出します。\n",
    "![](https://huggingface.co/blog/assets/52_bert_101/BERT-size-and-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "4.40.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-baseアーキテクチャのパラメータ説明\n",
    "\n",
    "## 1. 主要なアーキテクチャコンポーネント\n",
    "### トランスフォーマー層 (`num_hidden_layers: 12`)\n",
    "- BERT-baseは12のトランスフォーマーエンコーダー層を持つ\n",
    "- 各層は以下を含む:\n",
    "  * マルチヘッド自己注意機構\n",
    "  * フィードフォワードニューラルネットワーク\n",
    "  * レイヤー正規化\n",
    "  * 残差接続\n",
    "\n",
    "### 注意機構\n",
    "- `num_attention_heads: 12`\n",
    "  * 各層は12の注意ヘッドを持つ\n",
    "  * 各ヘッドは入力の異なる部分を処理\n",
    "- `hidden_size: 768`\n",
    "  * 隠れ状態の次元\n",
    "  * 各注意ヘッドは64次元のデータを処理 (768/12 = 64)\n",
    "\n",
    "### フィードフォワードネットワーク\n",
    "- `intermediate_size: 3072`\n",
    "  * フィードフォワードネットワークの中間層のサイズ\n",
    "  * 隠れサイズの4倍 (768 * 4 = 3072)\n",
    "  * シーケンス: 768 → 3072 → 768 (GELU活性化関数使用)\n",
    "\n",
    "## 2. その他の重要なパラメータ\n",
    "### 埋め込みとシーケンス\n",
    "- `vocab_size: 30522`\n",
    "  * トークナイザーの語彙サイズ\n",
    "- `max_position_embeddings: 512`\n",
    "  * モデルが処理できる最大シーケンス長\n",
    "- `type_vocab_size: 2`\n",
    "  * セグメント埋め込み用（文A/B）\n",
    "\n",
    "### モデル設定\n",
    "- `hidden_act: \"gelu\"`\n",
    "  * 使用される活性化関数\n",
    "- `layer_norm_eps: 1e-12`\n",
    "  * 数値の安定性のための小さな定数\n",
    "- `attention_probs_dropout_prob: 0.1`\n",
    "  * アテンション確率のドロップアウト率\n",
    "- `hidden_dropout_prob: 0.1`\n",
    "  * 全結合層のドロップアウト率\n",
    "\n",
    "### 位置情報\n",
    "- `position_embedding_type: \"absolute\"`\n",
    "  * 絶対位置埋め込みを使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embeddings\n",
    "BERTはテキストを数値ベクトルとして表現することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# 事前学習済みBERTモデルとトークナイザーの読み込み\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 入力テキスト\n",
    "sentence = \"BERT is a transformer-based model for NLP tasks.\"\n",
    "\n",
    "# 入力のエンコード\n",
    "inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# 隠れ状態の取得\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # 最終層の隠れ状態 (バッチサイズ, シーケンス長, 隠れ層の次元)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# [CLS]トークンの表現を文埋め込みとして取得\n",
    "sentence_embedding = hidden_states[:, 0, :]  # [CLS]埋め込み\n",
    "print(sentence_embedding.shape)  # 出力: torch.Size([1, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 768)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "   # 自然言語処理関連の文章\n",
    "   \"Deep learning models have transformed natural language processing.\",  # S2/S3のような技術的な文章\n",
    "   \"Transformers have revolutionized NLP tasks.\",\n",
    "   \"Natural language processing is advancing rapidly.\",\n",
    "   \n",
    "   # 天気関連の文章\n",
    "   \"The weather is sunny and warm today.\",\n",
    "   \"It might rain this afternoon.\",\n",
    "   \"The temperature will drop tomorrow.\",\n",
    "   \n",
    "   # スポーツ関連の文章\n",
    "   \"The basketball team won the championship.\",\n",
    "   \"The NBA finals were incredibly exciting.\",  # S7のようなバスケットボール専門の文章\n",
    "   \"The Lakers dominated the basketball season.\"  # S7のようなバスケットボール専門の文章\n",
    "]\n",
    "\n",
    "# すべての文章の埋め込みを取得\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "   for sentence in sentences:\n",
    "       inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "       outputs = model(**inputs).last_hidden_state\n",
    "       embeddings.append(outputs[:, 0, :])  # [CLS]トークンの埋め込みを取得\n",
    "\n",
    "# NumPy配列に変換して結合\n",
    "embeddings_np = np.vstack([emb.numpy() for emb in embeddings])\n",
    "print(embeddings_np.shape)  # 出力: (9, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 31456 (\\N{CJK UNIFIED IDEOGRAPH-7AE0}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 22475 (\\N{CJK UNIFIED IDEOGRAPH-57CB}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12417 (\\N{HIRAGANA LETTER ME}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 36796 (\\N{CJK UNIFIED IDEOGRAPH-8FBC}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12415 (\\N{HIRAGANA LETTER MI}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 20803 (\\N{CJK UNIFIED IDEOGRAPH-5143}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 21487 (\\N{CJK UNIFIED IDEOGRAPH-53EF}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 35222 (\\N{CJK UNIFIED IDEOGRAPH-8996}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 28982 (\\N{CJK UNIFIED IDEOGRAPH-7136}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 35328 (\\N{CJK UNIFIED IDEOGRAPH-8A00}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 35486 (\\N{CJK UNIFIED IDEOGRAPH-8A9E}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 20966 (\\N{CJK UNIFIED IDEOGRAPH-51E6}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 29702 (\\N{CJK UNIFIED IDEOGRAPH-7406}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 38306 (\\N{CJK UNIFIED IDEOGRAPH-95A2}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 36899 (\\N{CJK UNIFIED IDEOGRAPH-9023}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 22825 (\\N{CJK UNIFIED IDEOGRAPH-5929}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 27671 (\\N{CJK UNIFIED IDEOGRAPH-6C17}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12473 (\\N{KATAKANA LETTER SU}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12509 (\\N{KATAKANA LETTER PO}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12540 (\\N{KATAKANA-HIRAGANA PROLONGED SOUND MARK}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/var/folders/v0/5gx8ss_j2t55l30n8jm5d2t40000gn/T/ipykernel_3395/2289372731.py:36: UserWarning: Glyph 12484 (\\N{KATAKANA LETTER TU}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 31456 (\\N{CJK UNIFIED IDEOGRAPH-7AE0}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 22475 (\\N{CJK UNIFIED IDEOGRAPH-57CB}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12417 (\\N{HIRAGANA LETTER ME}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 36796 (\\N{CJK UNIFIED IDEOGRAPH-8FBC}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12415 (\\N{HIRAGANA LETTER MI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20803 (\\N{CJK UNIFIED IDEOGRAPH-5143}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21487 (\\N{CJK UNIFIED IDEOGRAPH-53EF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 35222 (\\N{CJK UNIFIED IDEOGRAPH-8996}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 28982 (\\N{CJK UNIFIED IDEOGRAPH-7136}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 35328 (\\N{CJK UNIFIED IDEOGRAPH-8A00}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 35486 (\\N{CJK UNIFIED IDEOGRAPH-8A9E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20966 (\\N{CJK UNIFIED IDEOGRAPH-51E6}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 29702 (\\N{CJK UNIFIED IDEOGRAPH-7406}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 38306 (\\N{CJK UNIFIED IDEOGRAPH-95A2}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 36899 (\\N{CJK UNIFIED IDEOGRAPH-9023}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 22825 (\\N{CJK UNIFIED IDEOGRAPH-5929}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 27671 (\\N{CJK UNIFIED IDEOGRAPH-6C17}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12473 (\\N{KATAKANA LETTER SU}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12509 (\\N{KATAKANA LETTER PO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12540 (\\N{KATAKANA-HIRAGANA PROLONGED SOUND MARK}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12484 (\\N{KATAKANA LETTER TU}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCAによる次元削減を適用（768次元から2次元へ）\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings_np)\n",
    "\n",
    "# グループごとに異なる色を使用して散布図を作成\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# グループごとに異なる色とマーカーでプロット\n",
    "colors = ['blue', 'green', 'red']  # 各グループの色を定義\n",
    "markers = ['o', 's', '^']  # マーカーの形状を定義: 丸、四角、三角\n",
    "\n",
    "for i in range(3):  # 3つのグループをループ\n",
    "   start_idx = i * 3\n",
    "   end_idx = start_idx + 3\n",
    "   plt.scatter(embeddings_2d[start_idx:end_idx, 0], \n",
    "              embeddings_2d[start_idx:end_idx, 1], \n",
    "              c=colors[i], \n",
    "              marker=markers[i],\n",
    "              label=f'グループ {i+1}')\n",
    "\n",
    "# 各点にラベルを追加\n",
    "# S1, S2などの形式で文章番号を表示\n",
    "for idx, sentence in enumerate(sentences):\n",
    "   plt.annotate(f\"S{idx+1}\", \n",
    "               (embeddings_2d[idx, 0], embeddings_2d[idx, 1]),\n",
    "               xytext=(5, 5), \n",
    "               textcoords='offset points',\n",
    "               fontsize=8)\n",
    "\n",
    "# プロットのカスタマイズ\n",
    "plt.title(\"文章埋め込みの2次元可視化\")  # タイトルの設定\n",
    "plt.legend(['自然言語処理関連', '天気関連', 'スポーツ関連'])  # 凡例の設定\n",
    "plt.grid(True, alpha=0.3)  # グリッドの表示（透明度0.3）\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Token Prediction\n",
    "BERTはマスクされたトークンを予測することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力テキスト: The [MASK] is shining brightly in the sky.\n",
      "BERTが予測した[MASK]の単語: sun\n",
      "\n",
      "上位5つの予測結果:\n",
      "sun: 0.605\n",
      "moon: 0.359\n",
      "sunset: 0.006\n",
      "star: 0.004\n",
      "city: 0.002\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "# 事前学習済みのマスク言語モデルを読み込む\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # 評価モードに設定\n",
    "\n",
    "# [MASK]トークンを含む入力テキストを準備\n",
    "text = \"The [MASK] is shining brightly in the sky.\"  # 「空で明るく輝いている[MASK]」\n",
    "\n",
    "# テキストをエンコード\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# [MASK]トークンの位置を取得\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# 予測を実行\n",
    "with torch.no_grad():\n",
    "   outputs = model(**inputs)\n",
    "   predictions = outputs.logits  # 予測結果（ロジット）を取得\n",
    "\n",
    "# 最も確率の高いトークンを取得\n",
    "predicted_token_id = predictions[0, mask_token_index].argmax(axis=-1)\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "print(f\"入力テキスト: {text}\")\n",
    "print(f\"BERTが予測した[MASK]の単語: {predicted_token}\")\n",
    "\n",
    "# 上位5つの予測結果を表示\n",
    "# softmax関数で確率に変換\n",
    "probs = torch.nn.functional.softmax(predictions[0, mask_token_index], dim=-1)\n",
    "# 確率が高い順に上位5つを取得\n",
    "top_5_tokens = torch.topk(probs, 5, dim=-1)\n",
    "\n",
    "print(\"\\n上位5つの予測結果:\")\n",
    "for token, prob in zip(top_5_tokens.indices[0], top_5_tokens.values[0]):\n",
    "   word = tokenizer.decode([token])\n",
    "   print(f\"{word}: {prob:.3f}\")  # 単語と確率を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Sentence Prediction\n",
    "BERTは2つの文間の関係性を判定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "文章1: The restaurant is famous.\n",
      "文章2: Jupiter is the largest planet.\n",
      "文章が関連している確率: 0.000\n",
      "文章が関連していない確率: 1.000\n",
      "\n",
      "文章1: The weather is very cold.\n",
      "文章2: There is snow everywhere.\n",
      "文章が関連している確率: 1.000\n",
      "文章が関連していない確率: 0.000\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForNextSentencePrediction\n",
    "# 事前学習済みのモデルを読み込む\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# 文章ペアの例を準備\n",
    "sentence_pairs = [\n",
    "   [\"The restaurant is famous.\", \"Jupiter is the largest planet.\"],  # 無関係な文章ペア\n",
    "   [\"The weather is very cold.\", \"There is snow everywhere.\"],     # 関連のある文章ペア\n",
    "]\n",
    "\n",
    "# 各文章ペアをテスト\n",
    "for sentences in sentence_pairs:\n",
    "   # 文章ペアをエンコード\n",
    "   encoding = tokenizer(sentences[0], sentences[1], return_tensors='pt', padding=True)\n",
    "   \n",
    "   # 予測を実行\n",
    "   with torch.no_grad():\n",
    "       outputs = model(**encoding)\n",
    "       predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "   \n",
    "   # 予測確率を取得\n",
    "   is_next_prob = predictions[0][0].item()\n",
    "   \n",
    "   print(f\"\\n文章1: {sentences[0]}\")\n",
    "   print(f\"文章2: {sentences[1]}\")\n",
    "   print(f\"文章が関連している確率: {is_next_prob:.3f}\")\n",
    "   print(f\"文章が関連していない確率: {1-is_next_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache() # メモリ解放, macos\n",
    "torch.cuda.empty_cache() # メモリ解放, CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER (Named Entity Recognition)\n",
    "BERTは文の中の固有名詞を識別することができる。\n",
    "![](https://miro.medium.com/v2/resize:fit:937/0*gDVxdYislF3CJVjq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classification\n",
    "BERTは文を分類することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9db43747fe4670920bf21c5da53b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfaa05eb8d041e680bff245b89912a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0145034014e949a6bb2c23f166f455cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd5f8fec1fd403db2fa5d949a29ef46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84402955f7e643cc99a64bde0da3d7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "テキスト分類結果:\n",
      "\n",
      "テキスト: This movie was terrible, I was so bored\n",
      "ネガティブ確率: 0.999\n",
      "ポジティブ確率: 0.001\n",
      "予測結果: ネガティブ\n",
      "\n",
      "テキスト: The restaurant served amazing food with great service\n",
      "ネガティブ確率: 0.003\n",
      "ポジティブ確率: 0.997\n",
      "予測結果: ポジティブ\n",
      "\n",
      "テキスト: The product quality is poor and it broke quickly\n",
      "ネガティブ確率: 0.994\n",
      "ポジティブ確率: 0.006\n",
      "予測結果: ネガティブ\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "def classify_text(text, model, tokenizer):\n",
    "    # テキストをエンコード\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # 予測を実行\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    return predictions.numpy()\n",
    "\n",
    "\n",
    "# 事前学習済みモデルとトークナイザーを読み込み\n",
    "model_name = \"textattack/bert-base-uncased-imdb\"  # IMDBレビュー用のBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# テストテキストを準備\n",
    "texts = [\n",
    "    \"This movie was terrible, I was so bored\",\n",
    "    \"The restaurant served amazing food with great service\",\n",
    "    \"The product quality is poor and it broke quickly\",\n",
    "]\n",
    "\n",
    "# 各テキストを分類\n",
    "print(\"\\nテキスト分類結果:\")\n",
    "for text in texts:\n",
    "    predictions = classify_text(text, model, tokenizer)\n",
    "    \n",
    "    print(f\"\\nテキスト: {text}\")\n",
    "    print(f\"ネガティブ確率: {predictions[0][0]:.3f}\")\n",
    "    print(f\"ポジティブ確率: {predictions[0][1]:.3f}\")\n",
    "    print(f\"予測結果: {'ポジティブ' if predictions[0][1] > predictions[0][0] else 'ネガティブ'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
